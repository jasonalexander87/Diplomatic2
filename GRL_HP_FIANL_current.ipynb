{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuPAKZIZYZJM//KC/z0g1U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1pzAtI0WNzeV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673819124301,"user_tz":-120,"elapsed":19686,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"821820b8-fda8-4869-f4b1-c9a71099dcdb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/Diplomatic2/Implementation\")\n","!ls"],"metadata":{"id":"2SC5soeTN_WG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673819127354,"user_tz":-120,"elapsed":641,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"016bc875-2301-453c-b0fc-617ec0da105f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[" AGNN_1\t\t\t     elliptic_txs_features.csv\t'GRL_FINAL (4).ipynb'\n"," AGNN_2\t\t\t     GAT_1\t\t\t GRL.ipynb\n"," AGNN_3\t\t\t     GAT_2\t\t\t Node2Vec\n"," data_balanced_1000.obj      GAT_2_1\t\t\t NoteBooks\n"," data_balanced_500.obj\t     GAT_3\t\t\t SAGE_1\n"," data.obj\t\t     GAT_FL_1\t\t\t SAGE_2\n"," DGI\t\t\t     GAT_RELU_1\t\t\t SAGE_3\n"," elliptic_txs_classes.csv    GAT_TEST\t\t\t stellar.obj\n"," elliptic_txs_edgelist.csv   GRL_2.ipynb\n"]}]},{"cell_type":"code","source":["#PYTORCH INSTALL\n","# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n","import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric"],"metadata":{"id":"FayKQOaNOGY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle   \n","import torch\n","from torch_geometric.data import Data\n","\n","fileObj = open('data.obj', 'rb')\n","data = pickle.load(fileObj)\n","fileObj.close()\n","print(data)"],"metadata":{"id":"4R7OZFngOIoW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673819168128,"user_tz":-120,"elapsed":2788,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"5b1d1c09-2e5a-4ffe-dfd5-43e6dc7b6147"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], n_id=[203769], train_mask=[203769], val_mask=[203769], test_mask=[203769])\n"]}]},{"cell_type":"code","source":["import copy\n","\n","data2 = copy.deepcopy(data)\n"],"metadata":{"id":"00_G8k2iv53U","executionInfo":{"status":"ok","timestamp":1673819169767,"user_tz":-120,"elapsed":268,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_index = data.train_mask.tolist()\n","val_index = data.val_mask.tolist()\n","test_index = data.test_mask.tolist()\n","print(type(train_index))\n","print(type(val_index))\n","print(type(test_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bdhfGulDYbF","executionInfo":{"status":"ok","timestamp":1673819175292,"user_tz":-120,"elapsed":242,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"f54592a6-9efd-4e01-8660-3275b10d1f8f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'list'>\n","<class 'list'>\n"]}]},{"cell_type":"code","source":["#USE GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRn0k6XmONk0","executionInfo":{"status":"ok","timestamp":1673819177465,"user_tz":-120,"elapsed":4,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"7ed46012-85cc-43a8-cdc5-a45617f124cf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["data = data.to(device)"],"metadata":{"id":"4-gHP0mYY9_Z","executionInfo":{"status":"ok","timestamp":1673819187279,"user_tz":-120,"elapsed":4569,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#EDW NA DW ALLES PERIPTWSEIS GIA BATCHES!!!\n","#Epishs na dw th lista me tous geitones\n","from torch_geometric.loader import NeighborLoader\n","\n","train_loader = NeighborLoader(data,num_neighbors=[-1, -1,-1], shuffle=True,batch_size=203769)\n","\n","counter = 0\n","for batch in train_loader:\n","\n","    print(len(batch.n_id))\n","    print(len(batch.y))\n","    print(type(batch))\n","    print(batch.test_mask)"],"metadata":{"id":"q7vdd4HDOW0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673819188501,"user_tz":-120,"elapsed":306,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"2ba66580-4f4e-45a7-e007-1e632f36ccfc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["203769\n","203769\n","<class 'torch_geometric.data.data.Data'>\n","tensor([False, False, False,  ..., False,  True, False], device='cuda:0')\n"]}]},{"cell_type":"code","source":["#SCRIPT 16\n","#METRICS\n","!pip install torchmetrics\n","from torchmetrics.classification import AUROC\n","from torchmetrics.classification import BinaryPrecision\n","from torchmetrics.classification import BinaryRecall\n","from torchmetrics.classification import BinaryConfusionMatrix\n","from torchmetrics.classification import MulticlassRecall\n","from torchmetrics.classification import MulticlassPrecision\n","from torchmetrics.classification import MulticlassAUROC\n","from torchmetrics.classification import BinaryF1Score\n","from torchmetrics.classification import MulticlassF1Score\n","from torchmetrics.classification import Accuracy\n","\n","confmat = BinaryConfusionMatrix()\n","recall = MulticlassRecall(num_classes=2, average=None)\n","precision = MulticlassPrecision(num_classes=2, average=None)\n","aucroc = MulticlassAUROC(task=\"multiclass\", num_classes=2, thresholds=None)\n","#f1 = BinaryF1Score(average=None)\n","f12 = MulticlassF1Score(num_classes=2, average=None)\n","accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n","\n","def conf_matrix(pred_y, y):\n","  #confmat = BinaryConfusionMatrix().to(device)\n","\n","  return confmat(pred_y, y)\n","\n","def brecall(pred_y, y):\n","  #recall = BinaryRecall().to(device)\n","  #recall = MulticlassRecall(num_classes=2, average=None).to(device)\n","\n","  return recall(pred_y, y)\n","\n","def bprecision(pred_y, y):\n","  #precision = MulticlassPrecision(num_classes=2, average=None).to(device)\n","\n","  return precision(pred_y, y)\n","\n","def auc_roc(pred_y, y):\n","  #aucroc = AUROC(task=\"binary\").to(device)\n","  #print('AUC ROC',pred_y[:10])\n","  #print('AUC ROC',y.shape)\n","  #aucroc = MulticlassAUROC(task=\"multiclass\", num_classes=2).to(device)\n","\n","  return aucroc(pred_y, y)\n","\n","def f1score(pred_y, y):\n","  #metric = BinaryF1Score(average=None).to(device)\n","\n","  return f12(pred_y, y)\n","\n","\n","def accuracy_score(pred_y, y):\n","    \n","    return accuracy(pred_y,y)"],"metadata":{"id":"cQC8280dOeLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TEST WITH FINAL LAYER\n","from torch_geometric.nn import GATConv\n","import torch.nn.functional as F\n","\n","layers_GATv2 = [1,2]\n","embe_GATv2 = [32,64]\n","loader_GATv2 = [0,1]\n","heads_GATv2 = [4,8]\n","weigths_GATv2 = [True,False]\n","GAT_HPsv2 = []\n","GAT_HPsv2.append(layers_GATv2)\n","GAT_HPsv2.append(embe_GATv2)\n","GAT_HPsv2.append(loader_GATv2)\n","GAT_HPsv2.append(heads_GATv2)\n","GAT_HPsv2.append(weigths_GATv2)\n","\n","class GAT2(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n","        super().__init__()\n","        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n","        # On the Pubmed dataset, use `heads` output heads in `conv2`.\n","        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1,concat=False, dropout=0.6)\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)  \n","\n","\n","    def forward(self, x, edge_index):\n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = F.elu(self.conv1(x, edge_index))\n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x, F.softmax(x, dim=1) "],"metadata":{"id":"g44DNNSacRrI","executionInfo":{"status":"ok","timestamp":1673819205353,"user_tz":-120,"elapsed":242,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LdEcSll4f-mk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_train_step(model, loss_fn, optimizer):\n","    # Builds function that performs a step in the train loop\n","    def train_step(data):\n","        # Sets model to TRAIN mode\n","        model.train()\n","        # Makes predictions\n","        logit, out = model(data.x,data.edge_index)\n","        # Computes loss\n","        loss = loss_fn(logit[data.train_mask], data.y[data.train_mask])\n","        # Computes gradients\n","        loss.backward()\n","        # Updates parameters and zeroes gradients\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        # Returns the loss\n","        return loss.item(), out.tolist()\n","    \n","    # Returns the function that will be called inside the train loop\n","    return train_step\n","\n","# Creates the train_step function for our model, loss function and optimizer\n","#train_step = make_train_step(model, loss_fn, optimizer)\n","#losses = []\n","\n","# For each epoch...\n","#for epoch in range(n_epochs):\n","    # Performs one train step and returns the corresponding loss\n","    #loss = train_step(x_train_tensor, y_train_tensor)\n","    #losses.append(loss)\n","    "],"metadata":{"id":"z3bDZGFEQEle","executionInfo":{"status":"ok","timestamp":1673819210165,"user_tz":-120,"elapsed":249,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["weigths = [2.5, 0.625]\n","imbalance = torch.FloatTensor(weigths).to(device)"],"metadata":{"id":"bMzZJy_gUlqs","executionInfo":{"status":"ok","timestamp":1673819221910,"user_tz":-120,"elapsed":250,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#NOT NEEDED\n","def argmax_list(list2argmax):\n","  list2return = []\n","\n","  for i in list2argmax:\n","    a = i[0]\n","    b = i[1]\n","    if a<=b:\n","      list2return.append(1)\n","    else:\n","      list2return.append(0)\n","\n","  return list2return"],"metadata":{"id":"trcMPXLfZFuC","executionInfo":{"status":"ok","timestamp":1673811401468,"user_tz":-120,"elapsed":270,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def metrics_computation(truth,pred_probs):\n","  print('METRICS ',len(pred_probs),len(truth),type(truth),type(pred_probs))\n","  #print(pred_probs[0],truth[0])\n","  #print(type(argmax_res),argmax_res.shape)\n","  #FOR AUCROC\n","  probs_tensor = torch.from_numpy(pred_probs)\n","  #print('tensor probs ',probs_tensor.shape)\n","  #FOR THE REST OF METRICS\n","  argmax_res = torch.argmax(probs_tensor,dim=1)\n","  #print('argmax ',argmax_res.shape)\n","  #FOR AUC AND REST TRYTH TENSOR\n","  truth_tensor = np.array(truth)\n","  truth_tensor = torch.from_numpy(truth_tensor)\n","  #print('TRUTH ',truth_tensor.shape)\n","\n","  #COMPUTE AUC ROC SCORE\n","  auc_score = auc_roc(probs_tensor,truth_tensor)\n","  #print('AUC SCORE ', auc_score)\n","\n","  #COMPUTE ACCURACY\n","  acc = accuracy_score(argmax_res,truth_tensor)\n","  #print('ACCURACY SCORE',acc)\n","\n","  #COMPUTE RECALL FOR BOTH CLASSES\n","  rec = brecall(argmax_res,truth_tensor)\n","  #print('RECALL SCORE ',rec) \n","\n","  #COMPUTE PRECISSION FOR BOTH CLASSES \n","  pre = bprecision(argmax_res,truth_tensor)\n","  #print('PRECISSION SCORE ',pre)\n","\n","  #COMPUTE F1 SCORE FOR BOTH CLASSES\n","  f1_score = f1score(argmax_res,truth_tensor)\n","  #print('F1 SCORE ',f1_score)\n","\n","  #COMPUTE CONFUSION MATRIX\n","  conf_m = conf_matrix(argmax_res,truth_tensor)\n","  #print('CONFUSION MATRIX ', conf_m)\n","\n","  return auc_score, acc, rec, pre, f1_score, conf_m\n","\n"],"metadata":{"id":"yytxj7fIvgff","executionInfo":{"status":"ok","timestamp":1673819229077,"user_tz":-120,"elapsed":259,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#TRAIN WITH DATA OBJECT\n","def train2(model,epochs,weigths):\n","\n","  if weigths == True:\n","\n","    print('WEIGTHS = ',weigths)\n","    criterion = torch.nn.CrossEntropyLoss(weight=imbalance)\n","  else:\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","  train_step = make_train_step(model, criterion, model.optimizer) \n","\n","  losses = []\n","  val_losses = []\n","  best_model = copy.deepcopy(model)\n","  best_val_loss = 10000\n","\n","  #METRICS VAL\n","  accuracy_v = []\n","  auc_v = []\n","  recall_score_v = []\n","  precission_score_v = []\n","  f1_v = []\n","  \n","  print('WORKING WITH TRAIN2')\n","  for epoch in range(epochs):\n","    \n","        \n","        #NA TO GYRISW SE SOFTMAX ANTI LOG\n","        loss, probs_train = train_step(data)\n","        losses.append(loss)\n","\n","        #print('TRAIN TENSOR ',type(probs_train),len(probs_train),probs_train[0])\n","        #print('PROBS TRAIN',probs_train[0])\n","        #tens = torch.tensor([0,1,1,1,0,0])\n","        #pred_train  = argmax_list(probs_train)\n","\n","        train_truth = data2.y[train_index].tolist()\n","        #print('train truth', type(train_truth))\n","\n","        #print('SIZE ',len(pred),type(pred))\n","        #pred = torch.tensor(pred)\n","        #print('SIZE ',len(pred),type(pred),pred.dtype)\n","        #pred = pred[train_index]\n","        #print('SIZE ',len(pred),type(pred),pred,pred.dtype)\n","        #print('B ',len(b),type(b),b.dtype)\n","        #print('LOSS',loss)\n","        \n","    #print('TEST ',type(probs),len(probs),probs[0])\n","    \n","        with torch.no_grad():\n","            \n","            model.eval()\n","\n","            logit, out = model(data.x,data.edge_index)\n","            val_loss = criterion(logit[data.val_mask], data.y[data.val_mask])\n","            val_losses.append(val_loss.item())\n","\n","            #print('PROBS VAL ',out.tolist()[0])\n","\n","            val_probs = out.tolist()\n","            val_probs = np.array(val_probs)\n","            val_probs = val_probs[val_index]\n","\n","            probs_train = np.array(probs_train)\n","            probs_train = probs_train[train_index]\n","            \n","\n","            val_truth = data2.y[val_index].tolist()\n","            auc_score_val, acc_val, rec_val, pre_val, f1_score_val, conf_m_val = metrics_computation(val_truth,val_probs)\n","            auc_score_train, acc_train, rec_train, pre_train, f1_score_train, conf_m_train = metrics_computation(train_truth,probs_train)\n","            \n","            print('AUC VAL',auc_score_val,' ACC VAL ',acc_val,' RECALL VAL ',rec_val, 'PRECI VAL ', pre_val,' F1 VAL ', f1_score_val,' CM VAL ',conf_m_val)\n","            print('AUC TRAIN',auc_score_train,' ACC TRAIN ',acc_train,' RECALL TRAIN ',rec_train, 'PRECI TRAIN ', pre_train,' F1 TRAIN ', f1_score_train,' CM TRAIN ',conf_m_train)\n","\n","        accuracy_v.append(acc_val.item())\n","        auc_v.append(auc_score_val.item())\n","        recall_score_v.append(rec_val.tolist())\n","        precission_score_v.append(pre_val.tolist())\n","        f1_v.append(f1_score_val.tolist())\n","\n","        if val_loss < best_val_loss:\n","          print('LOSSES',val_loss.item(),best_val_loss)\n","          best_model = copy.deepcopy(model)\n","          best_val_loss = copy.deepcopy(val_loss.item())\n","          print('NEW BEST///')     \n","  return losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v "],"metadata":{"id":"1tR5z9CaYQiJ","executionInfo":{"status":"ok","timestamp":1673819658817,"user_tz":-120,"elapsed":256,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#TRAIN WITH LOADER\n","def train1(model,epochs,weigths):\n","\n","  if weigths == True:\n","\n","    print('WEIGTHS = ',weigths)\n","    criterion = torch.nn.CrossEntropyLoss(weight=imbalance)\n","  else:\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","  train_step = make_train_step(model, criterion, model.optimizer) \n","\n","  losses = []\n","  val_losses = []\n","  best_model = copy.deepcopy(model)\n","  best_val_loss = 10000\n","\n","  #METRICS VAL\n","  accuracy_v = []\n","  auc_v = []\n","  recall_score_v = []\n","  precission_score_v = []\n","  f1_v = []\n","  \n","\n","  for epoch in range(epochs):\n","    for batch in train_loader:\n","        batch = batch.to(device)\n","        #NA TO GYRISW SE SOFTMAX ANTI LOG\n","        loss, probs_train = train_step(batch)\n","        losses.append(loss)\n","\n","        #print('TRAIN TENSOR ',type(probs_train),len(probs_train),probs_train[0])\n","        #print('PROBS TRAIN',probs_train[0])\n","        #tens = torch.tensor([0,1,1,1,0,0])\n","        #pred_train  = argmax_list(probs_train)\n","\n","        train_truth = data2.y[train_index].tolist()\n","        #print('train truth', type(train_truth))\n","\n","        #print('SIZE ',len(pred),type(pred))\n","        #pred = torch.tensor(pred)\n","        #print('SIZE ',len(pred),type(pred),pred.dtype)\n","        #pred = pred[train_index]\n","        #print('SIZE ',len(pred),type(pred),pred,pred.dtype)\n","        #print('B ',len(b),type(b),b.dtype)\n","        #print('LOSS',loss)\n","        \n","    #print('TEST ',type(probs),len(probs),probs[0])\n","    \n","    with torch.no_grad():\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            \n","            model.eval()\n","\n","            logit, out = model(batch.x,batch.edge_index)\n","            val_loss = criterion(logit[batch.val_mask], batch.y[batch.val_mask])\n","            val_losses.append(val_loss.item())\n","\n","            #print('PROBS VAL ',out.tolist()[0])\n","\n","            val_probs = out.tolist()\n","            val_probs = np.array(val_probs)\n","            val_probs = val_probs[val_index]\n","\n","            probs_train = np.array(probs_train)\n","            probs_train = probs_train[train_index]\n","            \n","\n","            val_truth = data2.y[val_index].tolist()\n","            auc_score_val, acc_val, rec_val, pre_val, f1_score_val, conf_m_val = metrics_computation(val_truth,val_probs)\n","            auc_score_train, acc_train, rec_train, pre_train, f1_score_train, conf_m_train = metrics_computation(train_truth,probs_train)\n","            \n","            print('AUC VAL',auc_score_val,' ACC VAL ',acc_val,' RECALL VAL ',rec_val, 'PRECI VAL ', pre_val,' F1 VAL ', f1_score_val)\n","            print('AUC TRAIN',auc_score_train,' ACC TRAIN ',acc_train,' RECALL TRAIN ',rec_train, 'PRECI TRAIN ', pre_train,' F1 TRAIN ', f1_score_train)\n","\n","        accuracy_v.append(acc_val.item())\n","        auc_v.append(auc_score_val.item())\n","        recall_score_v.append(rec_val.tolist())\n","        precission_score_v.append(pre_val.tolist())\n","        f1_v.append(f1_score_val.tolist())\n","\n","        if val_loss < best_val_loss:\n","          print('LOSSES',val_loss.item(),best_val_loss)\n","          best_model = copy.deepcopy(model)\n","          best_val_loss = copy.deepcopy(val_loss.item())\n","          print('NEW BEST///')     \n","  return losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v "],"metadata":{"id":"3LYgXaESSTjb","executionInfo":{"status":"ok","timestamp":1673819899250,"user_tz":-120,"elapsed":252,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#TEST FUNCTION\n","def test(model, data):\n","    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n","    with torch.no_grad():\n","      model.eval()\n","      _, out = model(data.x, data.edge_index)\n","      test_probs = out.tolist()\n","      test_probs = np.array(test_probs)\n","      test_probs = test_probs[test_index]\n","\n","      test_truth = data2.y[test_index].tolist()\n","\n","      auc_score_test, acc_test, rec_test, pre_test, f1_score_test, conf_m_test = metrics_computation(test_truth,test_probs)\n","\n","\n","\n","    return auc_score_test.item(), acc_test.item(), rec_test.tolist(), pre_test.tolist(), f1_score_test.tolist(), conf_m_test.tolist()"],"metadata":{"id":"Wv-dY53xcyKJ","executionInfo":{"status":"ok","timestamp":1673820811288,"user_tz":-120,"elapsed":235,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["gat6 = GAT2(165,64,2,8).to(device)\n","los, val_los, bm, a, au, r, p, f = train2(gat6,5,True)"],"metadata":{"id":"e2h-wPHQA1gq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a,b,c,d,e,f = test(bm,data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQE_gPNf1TLz","executionInfo":{"status":"ok","timestamp":1673820815351,"user_tz":-120,"elapsed":629,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"81ea8e59-cf23-45cd-e92b-e84cd403863c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["METRICS  29064 29064 <class 'list'> <class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["print(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uqiAF3KfXAD","executionInfo":{"status":"ok","timestamp":1673820823815,"user_tz":-120,"elapsed":244,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"929e0291-9646-4416-d6cf-f07339668647"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[[24, 2521], [33, 26486]]\n"]}]},{"cell_type":"code","source":["gat = GAT2(165,64,2,8).to(device)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","train_step = make_train_step(gat, loss_fn, gat.optimizer)\n","\n","losses = []\n","val_losses = []\n","n_epochs = 10\n","\n","for epoch in range(n_epochs):\n","    for batch in train_loader:\n","        batch = batch.to(device)\n","        \n","        loss, probs = train_step(batch)\n","        losses.append(loss)\n","        \n","    with torch.no_grad():\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            \n","            gat.eval()\n","\n","            logit, out = gat(batch.x,batch.edge_index)\n","            val_loss = loss_fn(logit[batch.val_mask], batch.y[batch.val_mask])\n","            val_losses.append(val_loss.item())"],"metadata":{"id":"glMTFD3fcAYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(losses)\n","print(val_losses)\n","print(probs[10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlLX6kEHjUj-","executionInfo":{"status":"ok","timestamp":1673706663348,"user_tz":-120,"elapsed":9,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"c8ff1e82-7cd8-4e11-e202-c954da95ba77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0175076723098755, 1.4170243740081787, 1.614760398864746, 1.2547857761383057, 0.9136817455291748, 0.6651911735534668, 0.9412901401519775, 0.8531443476676941, 0.6736094951629639, 0.6551904082298279]\n","[0.6734026074409485, 0.7447313070297241, 0.6016190052032471, 0.39293423295021057, 0.3158823847770691, 0.832743763923645, 0.758849561214447, 0.41440466046333313, 0.2922835350036621, 0.2934720814228058]\n","[-5.923264503479004, -0.002680045086890459]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","##########DOULEUEI NA KANW THN LISTA NUMPY ARRAY KAI NA PARW TA INDEXES \n","list_one = [3,4,5,6,7,8,9]\n","array = np.array(list_one)\n","print(array)\n","index = [0,3,4]\n","array2 = array[index]\n","print(array2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-hfDvgnIQ4R","executionInfo":{"status":"ok","timestamp":1673733175322,"user_tz":-120,"elapsed":11,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"61b633f7-9349-4efe-8c6c-aaa290a575ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3 4 5 6 7 8 9]\n","[3 6 7]\n"]}]},{"cell_type":"code","source":["def argmax_list(list2argmax):\n","  list2return = []\n","\n","  for i in list2argmax:\n","    a = i[0]\n","    b = i[1]\n","    if a<=b:\n","      list2return.append(1)\n","    else:\n","      list2return.append(0)\n","\n","  return list2return\n"],"metadata":{"id":"6dB2EI37KgIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_one = [[0.2,0.1],[0.4,0.6],[0.6,0.8],[0.4,0.6]]\n","index = [0,1]\n","res = argmax_list(list_one)\n","print(res)\n","res2 = res[0,1]\n","print(res2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"nq8T4nYQLUjd","executionInfo":{"status":"error","timestamp":1673733784964,"user_tz":-120,"elapsed":384,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"85f8f117-e7e7-4f46-8785-5a17d3f7ba82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 1, 1]\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-830ba8e05c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"]}]}]}