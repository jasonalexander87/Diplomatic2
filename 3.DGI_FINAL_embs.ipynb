{"cells":[{"cell_type":"markdown","metadata":{"id":"WJMeM2_flQbf"},"source":["Σε αυτό το notebook υλοποιούμε τον αλγόριθμο DGI για τα καλύτερα μοντέλα που προέκυψαν απο το προηγούμενο. Τα πειράματα για κάθε μοντέλο είναι δύο το πρώτο με χρήση του encoder και βάρη σε κατάσταση freeze και το δεύτερο με τα βάρη του encoder εκπαιδεύσιμα. Αρχικά φορτώνουμε το data object που αντιστοιχεί στο σενάριο imbalance καθώς αυτό έδωσε τα καλύτερα αποτελέσματα. Στην συνέχεια χρησιμοποιούμε τα δύο train functions που έιχαμε και στο προηγούμενο. Στην συνέχεια δημιουργούμε το μοντέλο για κάθε περίπτωση και το train function του DGI και το εκπαιδεύουμε για 200 εποχές. Μετά πέρνουμε το αντικείμενο encoder από το μοντέλο dgi και δημιουργούμε τον classifier. Στην συνέχεια τρέχουμε τα δύο σενάρια και αποθηκεύουμε τα αποτελέσματα για περεταίρω επεξεργασία."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFIGx4c_lQbr","executionInfo":{"status":"ok","timestamp":1675719510214,"user_tz":-120,"elapsed":33169,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"0c2de9a9-4e4a-4043-c5d8-c810fc2813c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJQPrQlvnu6w","outputId":"da998a9b-57ee-4d4d-b7a5-94617248c653","executionInfo":{"status":"ok","timestamp":1675719516456,"user_tz":-120,"elapsed":1388,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" AGNN_1\t\t\t      elliptic_txs_features.csv   GRL.ipynb\n"," AGNN_2\t\t\t      FINAL_RESULTS\t\t  Node2Vec\n"," AGNN_3\t\t\t      GAT_1\t\t\t  node_deg.obj\n"," DATA\t\t\t      GAT_2\t\t\t  node_d.obj\n"," data_balanced_1000.obj       GAT_2_1\t\t\t  NoteBooks\n"," data_balanced_500.obj\t      GAT_3\t\t\t  project\n"," data_node_deg_features.obj   GAT_FL_1\t\t\t  requirements.txt\n"," data.obj\t\t      GAT_RELU_1\t\t  SAGE_1\n"," DGI\t\t\t      GAT_TEST\t\t\t  SAGE_2\n"," elliptic_txs_classes.csv     GRL_2.ipynb\t\t  SAGE_3\n"," elliptic_txs_edgelist.csv   'GRL_FINAL (4).ipynb'\t  stellar.obj\n"]}],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/Diplomatic2/Implementation\")\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSL8P7A2nvv3"},"outputs":[],"source":["#PYTORCH INSTALL\n","# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n","import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16vvWz1bn4gL","outputId":"bb1a0b13-3577-48d3-9a2e-aaafaf9795fa","executionInfo":{"status":"ok","timestamp":1675719565960,"user_tz":-120,"elapsed":2407,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], n_id=[203769], train_mask=[203769], val_mask=[203769], test_mask=[203769])\n"]}],"source":["#LOAD DATA OBJECT\n","import pickle   \n","import torch\n","from torch_geometric.data import Data\n","\n","fileObj = open('data.obj', 'rb')\n","data = pickle.load(fileObj)\n","fileObj.close()\n","print(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkL1GzFvn-SO","outputId":"363722df-c93b-4fd8-92ec-d7edf117b0b5","executionInfo":{"status":"ok","timestamp":1675719570396,"user_tz":-120,"elapsed":696,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["#USE GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZTIuVOeoCb5"},"outputs":[],"source":["data = data.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lsG3LePoIuh","outputId":"27e8f9b3-6fc0-4f30-f197-35acab5f7ce4","executionInfo":{"status":"ok","timestamp":1675719579741,"user_tz":-120,"elapsed":688,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["203769\n","203769\n","<class 'torch_geometric.data.data.Data'>\n","tensor([False, False, False,  ..., False, False, False], device='cuda:0')\n"]}],"source":["#EDW NA DW ALLES PERIPTWSEIS GIA BATCHES!!!\n","#Epishs na dw th lista me tous geitones\n","from torch_geometric.loader import NeighborLoader\n","\n","train_loader = NeighborLoader(data,num_neighbors=[-1, -1,-1], shuffle=True,batch_size=203769)\n","\n","counter = 0\n","for batch in train_loader:\n","\n","    print(len(batch.n_id))\n","    print(len(batch.y))\n","    print(type(batch))\n","    print(batch.test_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCoYeOpOoJjS"},"outputs":[],"source":["#SCRIPT 1\n","#DHMIOURGIA MONTELOY SAGE KAI ANTISTOIXOU CLASSIFIER\n","from torch_geometric.nn import DeepGraphInfomax, SAGEConv\n","import torch.nn.functional as F\n","\n","class GraphSAGE(torch.nn.Module):\n","  \"\"\"GraphSAGE\"\"\"\n","  def __init__(self):\n","    super().__init__()\n","    \n","    self.sage1 = SAGEConv(165, 256)\n","    self.sage2 = SAGEConv(256, 128)\n","    self.sage3 = SAGEConv(128, 128)\n","    \n","  def forward(self, x, edge_index):\n","\n","      h = self.sage1(x, edge_index)\n","      h = torch.relu(h)\n","      h = F.dropout(h, p=0.5, training=self.training)\n","      h = self.sage2(h, edge_index)\n","      h = torch.relu(h)\n","      h = F.dropout(h, p=0.2, training=self.training)\n","      h = self.sage3(h, edge_index)\n","      h = torch.relu(h)\n","\n","      return h\n","\n","class SAGE_Classifier(torch.nn.Module):\n","  \"\"\"GraphSAGE\"\"\"\n","  def __init__(self,encoder):\n","    super().__init__()\n","\n","    self.encoder = encoder\n","    #self.encoder.requires_grad_(False)\n","    self.linear = torch.nn.Linear(128,2)\n","    self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)\n","    \n","  def forward(self, x, edge_index):\n","\n","      h = self.encoder(x, edge_index)\n","      h = self.linear(h)\n","\n","      return h, F.softmax(h, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXRzqXinwOJP"},"outputs":[],"source":["import copy\n","\n","data2 = copy.deepcopy(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KhYEUNMHwajy","outputId":"c3fc225b-fa3f-45b0-a37a-5d8ce4739198","executionInfo":{"status":"ok","timestamp":1675719595501,"user_tz":-120,"elapsed":9,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'list'>\n","<class 'list'>\n"]}],"source":["#TRAI/VAL/TEST MASKS\n","train_index = data.train_mask.tolist()\n","val_index = data.val_mask.tolist()\n","test_index = data.test_mask.tolist()\n","print(type(train_index))\n","print(type(val_index))\n","print(type(test_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFwy3DGrvN1K"},"outputs":[],"source":["#DEBUGGING CODE WORKS!!!!\n","model1 = GraphSAGE()\n","print(model1)\n","model2 = SAGE_Classifier(model1)\n","print(model2)\n","losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v = train1(model2,1,False)\n","auc_score_GAT, acc_GAT, rec_GAT, pre_GAT, f1_GAT, conf_m_GAT = test(best_model,data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Q38UywJw7OU"},"outputs":[],"source":["#DEBUGGING CODE WORKS\n","model3 = GATmodel()\n","print(model3)\n","model4 = GAT_Classifier(model3)\n","print(model4)\n","losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v = train2(model4,1,False)\n","auc_score_GAT, acc_GAT, rec_GAT, pre_GAT, f1_GAT, conf_m_GAT = test(best_model,data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDx6VFSopmRN"},"outputs":[],"source":["#SCRIPT 2\n","#GAT MODEL KAI ANTISTOIXOS CLASSIFIER\n","from torch_geometric.nn import DeepGraphInfomax, GATConv\n","import torch.nn.functional as F\n","import copy\n","\n","class GATmodel(torch.nn.Module):\n","    def __init__(self):\n","        super(GATmodel, self).__init__()\n","        self.hid = 32\n","        self.in_head = 8\n","      \n","        self.conv1 = GATConv(165, self.hid, heads=self.in_head, dropout=0.6)\n","        self.conv = GATConv(self.hid*self.in_head, self.hid, heads=self.in_head,concat=False, dropout=0.6)\n","        #self.conv2 = GATConv(self.hid*self.in_head, self.hid, heads=self.in_head, dropout=0.6)\n","       \n","          \n","    def forward(self,x, edge_index):\n","        \n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = self.conv1(x, edge_index)\n","        x = F.elu(x)\n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = self.conv(x, edge_index)\n","        x = F.elu(x)\n","        \n","        return x   \n","\n","\n","class GAT_Classifier(torch.nn.Module):\n","  def __init__(self,encoder):\n","    super().__init__()\n","\n","    self.encoder = encoder\n","    #self.encoder.requires_grad_(False)\n","    self.linear = torch.nn.Linear(32,2)\n","    self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)\n","    \n","  def forward(self, x, edge_index):\n","#NA BALW DROP OUT SE OLA\n","      h = self.encoder(x, edge_index)\n","      h = self.linear(h)\n","\n","      return h, F.softmax(h, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7kj78TIq7xB"},"outputs":[],"source":["#SCRIPT 3\n","#AGNN MODEL KAI ANTISTOIXOS CLASSIFIER\n","from torch_geometric.nn import DeepGraphInfomax, AGNNConv\n","import torch.nn.functional as F\n","\n","class AGNNmodel(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.hidden = 64\n","\n","        self.lin1 = torch.nn.Linear(165, self.hidden)\n","        self.prop1 = AGNNConv(requires_grad=False)\n","        self.prop2 = AGNNConv(requires_grad=True)\n","\n","\n","    def forward(self, x, edge_index):\n","\n","        x = F.dropout(x, training=self.training)\n","        x = F.relu(self.lin1(x))\n","        x = self.prop1(x, edge_index)\n","        x = self.prop2(x, edge_index)\n","\n","        return x \n","\n","class AGNN_Classifier(torch.nn.Module):\n","  def __init__(self,encoder):\n","    super().__init__()\n","\n","    self.encoder = encoder\n","    #self.encoder.requires_grad_(False)\n","    self.linear = torch.nn.Linear(64,2)\n","    self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)\n","    \n","  def forward(self, x, edge_index):\n","\n","      h = self.encoder(x, edge_index)\n","      h = self.linear(h)\n","\n","      return h, F.softmax(h, dim=1)        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3rYU0XorPke"},"outputs":[],"source":["#SCRIPT 4\n","#METRICS\n","!pip install torchmetrics\n","from torchmetrics.classification import AUROC\n","from torchmetrics.classification import BinaryPrecision\n","from torchmetrics.classification import BinaryRecall\n","from torchmetrics.classification import BinaryConfusionMatrix\n","from torchmetrics.classification import MulticlassRecall\n","from torchmetrics.classification import MulticlassPrecision\n","from torchmetrics.classification import MulticlassAUROC\n","from torchmetrics.classification import BinaryF1Score\n","from torchmetrics.classification import MulticlassF1Score\n","from torchmetrics.classification import Accuracy\n","\n","confmat = BinaryConfusionMatrix()\n","recall = MulticlassRecall(num_classes=2, average=None)\n","precision = MulticlassPrecision(num_classes=2, average=None)\n","aucroc = MulticlassAUROC(task=\"multiclass\", num_classes=2, thresholds=None)\n","#f1 = BinaryF1Score(average=None)\n","f12 = MulticlassF1Score(num_classes=2, average=None)\n","accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n","\n","def conf_matrix(pred_y, y):\n","  #confmat = BinaryConfusionMatrix().to(device)\n","\n","  return confmat(pred_y, y)\n","\n","def brecall(pred_y, y):\n","  #recall = BinaryRecall().to(device)\n","  #recall = MulticlassRecall(num_classes=2, average=None).to(device)\n","\n","  return recall(pred_y, y)\n","\n","def bprecision(pred_y, y):\n","  #precision = MulticlassPrecision(num_classes=2, average=None).to(device)\n","\n","  return precision(pred_y, y)\n","\n","def auc_roc(pred_y, y):\n","  #aucroc = AUROC(task=\"binary\").to(device)\n","  #print('AUC ROC',pred_y[:10])\n","  #print('AUC ROC',y.shape)\n","  #aucroc = MulticlassAUROC(task=\"multiclass\", num_classes=2).to(device)\n","\n","  return aucroc(pred_y, y)\n","\n","def f1score(pred_y, y):\n","  #metric = BinaryF1Score(average=None).to(device)\n","\n","  return f12(pred_y, y)\n","\n","\n","def accuracy_score(pred_y, y):\n","    \n","    return accuracy(pred_y,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDwum3sMrhA6"},"outputs":[],"source":["#SCRIPT 5\n","#TRAIN ONE EPOCH\n","def make_train_step(model, loss_fn, optimizer):\n","    # Builds function that performs a step in the train loop\n","    def train_step(data):\n","        # Sets model to TRAIN mode\n","        model.train()\n","        # Makes predictions\n","        logit, out = model(data.x,data.edge_index)\n","        # Computes loss\n","        loss = loss_fn(logit[data.train_mask], data.y[data.train_mask])\n","        # Computes gradients\n","        loss.backward()\n","        # Updates parameters and zeroes gradients\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        # Returns the loss\n","        return loss.item(), out.tolist()\n","    \n","    # Returns the function that will be called inside the train loop\n","    return train_step\n","\n","# Creates the train_step function for our model, loss function and optimizer\n","#train_step = make_train_step(model, loss_fn, optimizer)\n","#losses = []\n","\n","# For each epoch...\n","#for epoch in range(n_epochs):\n","    # Performs one train step and returns the corresponding loss\n","    #loss = train_step(x_train_tensor, y_train_tensor)\n","    #losses.append(loss)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PB-nyfdHr1Z1"},"outputs":[],"source":["#SCRIPT 4\n","#FUNCTION TO RETURN METRICS\n","import numpy as np\n","\n","def metrics_computation(truth,pred_probs):\n","  print('METRICS ',len(pred_probs),len(truth),type(truth),type(pred_probs))\n","  #print(pred_probs[0],truth[0])\n","  #print(type(argmax_res),argmax_res.shape)\n","  #FOR AUCROC\n","  probs_tensor = torch.from_numpy(pred_probs)\n","  #print('tensor probs ',probs_tensor.shape)\n","  #FOR THE REST OF METRICS\n","  argmax_res = torch.argmax(probs_tensor,dim=1)\n","  #print('argmax ',argmax_res.shape)\n","  #FOR AUC AND REST TRYTH TENSOR\n","  truth_tensor = np.array(truth)\n","  truth_tensor = torch.from_numpy(truth_tensor)\n","  #print('TRUTH ',truth_tensor.shape)\n","\n","  #COMPUTE AUC ROC SCORE\n","  auc_score = auc_roc(probs_tensor,truth_tensor)\n","  #print('AUC SCORE ', auc_score)\n","\n","  #COMPUTE ACCURACY\n","  acc = accuracy_score(argmax_res,truth_tensor)\n","  #print('ACCURACY SCORE',acc)\n","\n","  #COMPUTE RECALL FOR BOTH CLASSES\n","  rec = brecall(argmax_res,truth_tensor)\n","  #print('RECALL SCORE ',rec) \n","\n","  #COMPUTE PRECISSION FOR BOTH CLASSES \n","  pre = bprecision(argmax_res,truth_tensor)\n","  #print('PRECISSION SCORE ',pre)\n","\n","  #COMPUTE F1 SCORE FOR BOTH CLASSES\n","  f1_score = f1score(argmax_res,truth_tensor)\n","  #print('F1 SCORE ',f1_score)\n","\n","  #COMPUTE CONFUSION MATRIX\n","  conf_m = conf_matrix(argmax_res,truth_tensor)\n","  #print('CONFUSION MATRIX ', conf_m)\n","\n","  return auc_score, acc, rec, pre, f1_score, conf_m\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eqx_JuCMsJPu"},"outputs":[],"source":["#SCRIPT 5\n","#TRAIN FUNCTION FOR GAT/AGNN\n","#TRAIN WITH DATA OBJECT\n","def train2(model,epochs,weigths):\n","\n","  if weigths == True:\n","\n","    print('WEIGTHS = ',weigths)\n","    criterion = torch.nn.CrossEntropyLoss(weight=imbalance)\n","  else:\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","  train_step = make_train_step(model, criterion, model.optimizer) \n","\n","  losses = []\n","  val_losses = []\n","  best_model = copy.deepcopy(model)\n","  best_val_loss = 10000\n","\n","  #METRICS VAL\n","  accuracy_v = []\n","  auc_v = []\n","  recall_score_v = []\n","  precission_score_v = []\n","  f1_v = []\n","  \n","  print('WORKING WITH TRAIN2')\n","  for epoch in range(epochs):\n","    \n","        \n","        #NA TO GYRISW SE SOFTMAX ANTI LOG\n","        loss, probs_train = train_step(data)\n","        losses.append(loss)\n","\n","        #print('TRAIN TENSOR ',type(probs_train),len(probs_train),probs_train[0])\n","        #print('PROBS TRAIN',probs_train[0])\n","        #tens = torch.tensor([0,1,1,1,0,0])\n","        #pred_train  = argmax_list(probs_train)\n","\n","        train_truth = data2.y[train_index].tolist()\n","        #print('train truth', type(train_truth))\n","\n","        #print('SIZE ',len(pred),type(pred))\n","        #pred = torch.tensor(pred)\n","        #print('SIZE ',len(pred),type(pred),pred.dtype)\n","        #pred = pred[train_index]\n","        #print('SIZE ',len(pred),type(pred),pred,pred.dtype)\n","        #print('B ',len(b),type(b),b.dtype)\n","        #print('LOSS',loss)\n","        \n","    #print('TEST ',type(probs),len(probs),probs[0])\n","    \n","        with torch.no_grad():\n","            \n","            model.eval()\n","\n","            logit, out = model(data.x,data.edge_index)\n","            val_loss = criterion(logit[data.val_mask], data.y[data.val_mask])\n","            val_losses.append(val_loss.item())\n","\n","            #print('PROBS VAL ',out.tolist()[0])\n","\n","            val_probs = out.tolist()\n","            val_probs = np.array(val_probs)\n","            val_probs = val_probs[val_index]\n","\n","            probs_train = np.array(probs_train)\n","            probs_train = probs_train[train_index]\n","            \n","\n","            val_truth = data2.y[val_index].tolist()\n","            auc_score_val, acc_val, rec_val, pre_val, f1_score_val, conf_m_val = metrics_computation(val_truth,val_probs)\n","            auc_score_train, acc_train, rec_train, pre_train, f1_score_train, conf_m_train = metrics_computation(train_truth,probs_train)\n","            \n","            print('AUC VAL',auc_score_val,' ACC VAL ',acc_val,' RECALL VAL ',rec_val, 'PRECI VAL ', pre_val,' F1 VAL ', f1_score_val,' CM VAL ',conf_m_val)\n","            print('AUC TRAIN',auc_score_train,' ACC TRAIN ',acc_train,' RECALL TRAIN ',rec_train, 'PRECI TRAIN ', pre_train,' F1 TRAIN ', f1_score_train,' CM TRAIN ',conf_m_train)\n","\n","        accuracy_v.append(acc_val.item())\n","        auc_v.append(auc_score_val.item())\n","        recall_score_v.append(rec_val.tolist())\n","        precission_score_v.append(pre_val.tolist())\n","        f1_v.append(f1_score_val.tolist())\n","\n","        if val_loss < best_val_loss:\n","          print('LOSSES',val_loss.item(),best_val_loss)\n","          best_model = copy.deepcopy(model)\n","          best_val_loss = copy.deepcopy(val_loss.item())\n","          print('NEW BEST///')     \n","  return losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F57rlHezsTz8"},"outputs":[],"source":["#SCRIPT 5\n","#TRAIN FUNCTION FOR SAGE\n","#TRAIN WITH LOADER\n","def train1(model,epochs,weigths):\n","\n","  if weigths == True:\n","\n","    print('WEIGTHS = ',weigths)\n","    criterion = torch.nn.CrossEntropyLoss(weight=imbalance)\n","  else:\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","  train_step = make_train_step(model, criterion, model.optimizer) \n","\n","  losses = []\n","  val_losses = []\n","  best_model = copy.deepcopy(model)\n","  best_val_loss = 10000\n","\n","  #METRICS VAL\n","  accuracy_v = []\n","  auc_v = []\n","  recall_score_v = []\n","  precission_score_v = []\n","  f1_v = []\n","  \n","\n","  for epoch in range(epochs):\n","    for batch in train_loader:\n","        batch = batch.to(device)\n","        #NA TO GYRISW SE SOFTMAX ANTI LOG\n","        loss, probs_train = train_step(batch)\n","        losses.append(loss)\n","\n","        #print('TRAIN TENSOR ',type(probs_train),len(probs_train),probs_train[0])\n","        #print('PROBS TRAIN',probs_train[0])\n","        #tens = torch.tensor([0,1,1,1,0,0])\n","        #pred_train  = argmax_list(probs_train)\n","\n","        train_truth = data2.y[train_index].tolist()\n","        #print('train truth', type(train_truth))\n","\n","        #print('SIZE ',len(pred),type(pred))\n","        #pred = torch.tensor(pred)\n","        #print('SIZE ',len(pred),type(pred),pred.dtype)\n","        #pred = pred[train_index]\n","        #print('SIZE ',len(pred),type(pred),pred,pred.dtype)\n","        #print('B ',len(b),type(b),b.dtype)\n","        #print('LOSS',loss)\n","        \n","    #print('TEST ',type(probs),len(probs),probs[0])\n","    \n","    with torch.no_grad():\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            \n","            model.eval()\n","\n","            logit, out = model(batch.x,batch.edge_index)\n","            val_loss = criterion(logit[batch.val_mask], batch.y[batch.val_mask])\n","            val_losses.append(val_loss.item())\n","\n","            #print('PROBS VAL ',out.tolist()[0])\n","\n","            val_probs = out.tolist()\n","            val_probs = np.array(val_probs)\n","            val_probs = val_probs[val_index]\n","\n","            probs_train = np.array(probs_train)\n","            probs_train = probs_train[train_index]\n","            \n","\n","            val_truth = data2.y[val_index].tolist()\n","            auc_score_val, acc_val, rec_val, pre_val, f1_score_val, conf_m_val = metrics_computation(val_truth,val_probs)\n","            auc_score_train, acc_train, rec_train, pre_train, f1_score_train, conf_m_train = metrics_computation(train_truth,probs_train)\n","            \n","            print('AUC VAL',auc_score_val,' ACC VAL ',acc_val,' RECALL VAL ',rec_val, 'PRECI VAL ', pre_val,' F1 VAL ', f1_score_val)\n","            print('AUC TRAIN',auc_score_train,' ACC TRAIN ',acc_train,' RECALL TRAIN ',rec_train, 'PRECI TRAIN ', pre_train,' F1 TRAIN ', f1_score_train)\n","\n","        accuracy_v.append(acc_val.item())\n","        auc_v.append(auc_score_val.item())\n","        recall_score_v.append(rec_val.tolist())\n","        precission_score_v.append(pre_val.tolist())\n","        f1_v.append(f1_score_val.tolist())\n","\n","        if val_loss < best_val_loss:\n","          print('LOSSES',val_loss.item(),best_val_loss)\n","          best_model = copy.deepcopy(model)\n","          best_val_loss = copy.deepcopy(val_loss.item())\n","          print('NEW BEST///')     \n","  return losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Aro70NAsjZV"},"outputs":[],"source":["#SCRIPT 5\n","#TEST FUNCTION\n","def test(model, data):\n","    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n","    with torch.no_grad():\n","      model.eval()\n","      _, out = model(data.x, data.edge_index)\n","      test_probs = out.tolist()\n","      test_probs = np.array(test_probs)\n","      test_probs = test_probs[test_index]\n","\n","      test_truth = data2.y[test_index].tolist()\n","\n","      auc_score_test, acc_test, rec_test, pre_test, f1_score_test, conf_m_test = metrics_computation(test_truth,test_probs)\n","\n","\n","\n","    return auc_score_test.item(), acc_test.item(), rec_test.tolist(), pre_test.tolist(), f1_score_test.tolist(), conf_m_test.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62oL-rfHsqQg"},"outputs":[],"source":["#SCRIPT 6\n","#TRAIN ENCODER WITH DGI\n","#CORRUPTION TO CREATE ANOTHER GRAPH\n","#SUMMARY FUNCTION IS SIGMOID OF POS_Z.MEAN() DOUBLE CHECKED\n","#encoder_SAGE = GraphSAGE()\n","#print(encoder_SAGE)\n","#encoder_GAT = GATmodel()\n","#print(encoder_GAT)\n","#encoder_AGNN = AGNNmodel()\n","#print(encoder_AGNN)\n","\n","def corruption(x, edge_index):\n","    return x[torch.randperm(x.size(0))], edge_index\n","\n","model_dgi = DeepGraphInfomax(hidden_channels=128, encoder=GraphSAGE(),summary=lambda z, *args, **kwargs: torch.sigmoid(z.mean(dim=0)),corruption=corruption).to(device)\n","\n","optimizer = torch.optim.Adam(model_dgi.parameters(), lr=0.001)\n","\n","def train_dgi():\n","    model_dgi.train()\n","    optimizer.zero_grad()\n","    pos_z, neg_z, summary = model_dgi(data.x, data.edge_index)\n","    loss = model_dgi.loss(pos_z, neg_z, summary)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84nsfLvf2dJh","outputId":"36716580-2984-461c-ee8a-929245610020","executionInfo":{"status":"ok","timestamp":1675719735781,"user_tz":-120,"elapsed":1632,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["AGNN_DGI.emb  GAT_DGI.emb\n"]}],"source":["os.chdir(\"/content/drive/MyDrive/Diplomatic2/Implementation/FINAL_RESULTS/DGI_EMB\")\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GUvLCkisznb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675719795229,"user_tz":-120,"elapsed":50749,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"2588e1c0-adfe-49ed-b9e8-e63e2ebb7db0"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.3983526229858398\n","1.3878659009933472\n","1.4153600931167603\n","1.3775641918182373\n","1.38112211227417\n","1.3857982158660889\n","1.376237154006958\n","1.3689396381378174\n","1.366485357284546\n","1.3647058010101318\n","1.3595751523971558\n","1.3491764068603516\n","1.343616247177124\n","1.3358144760131836\n","1.3205673694610596\n","1.3122589588165283\n","1.2965821027755737\n","1.2865231037139893\n","1.2630763053894043\n","1.2534689903259277\n","1.2327702045440674\n","1.2112398147583008\n","1.2071101665496826\n","1.1937062740325928\n","1.1728644371032715\n","1.1587374210357666\n","1.1538641452789307\n","1.1343045234680176\n","1.125657558441162\n","1.117638111114502\n","1.1021983623504639\n","1.0927391052246094\n","1.0806639194488525\n","1.06976318359375\n","1.053657054901123\n","1.0516541004180908\n","1.0409750938415527\n","1.0256233215332031\n","1.0132330656051636\n","1.0037477016448975\n","0.9963935613632202\n","0.9838992953300476\n","0.9734538793563843\n","0.9661258459091187\n","0.9527742862701416\n","0.9422775506973267\n","0.9392518997192383\n","0.9249292612075806\n","0.9237951040267944\n","0.9094126224517822\n","0.8957882523536682\n","0.8838517665863037\n","0.8810778260231018\n","0.8813212513923645\n","0.8730202317237854\n","0.857626736164093\n","0.8461561799049377\n","0.8475488424301147\n","0.8393816947937012\n","0.8236916065216064\n","0.8235753178596497\n","0.8195502758026123\n","0.8006811141967773\n","0.8068074584007263\n","0.7993940114974976\n","0.7864423990249634\n","0.7858650088310242\n","0.7784299850463867\n","0.7714880704879761\n","0.7728744149208069\n","0.7680023908615112\n","0.7575433254241943\n","0.7546960711479187\n","0.7491632699966431\n","0.7401479482650757\n","0.7404560446739197\n","0.7341490983963013\n","0.7292419075965881\n","0.7287960648536682\n","0.7269141674041748\n","0.718302845954895\n","0.7164168357849121\n","0.7146344184875488\n","0.7080878019332886\n","0.7104895114898682\n","0.7040129899978638\n","0.6916637420654297\n","0.6977454423904419\n","0.6888707876205444\n","0.6913999319076538\n","0.6854797601699829\n","0.6800425052642822\n","0.6758928894996643\n","0.6749348640441895\n","0.6720681190490723\n","0.6711888909339905\n","0.6698799133300781\n","0.6619638204574585\n","0.6658267974853516\n","0.6590944528579712\n","0.6536043882369995\n","0.6565335988998413\n","0.652026891708374\n","0.6492582559585571\n","0.6509461402893066\n","0.6427717804908752\n","0.6450483798980713\n","0.636906087398529\n","0.6389981508255005\n","0.6340633630752563\n","0.6326454877853394\n","0.6263450384140015\n","0.6280930638313293\n","0.6277523040771484\n","0.622822642326355\n","0.6219780445098877\n","0.6201924085617065\n","0.618881344795227\n","0.6152850389480591\n","0.616960883140564\n","0.6118327379226685\n","0.61257004737854\n","0.6094121932983398\n","0.6092606782913208\n","0.6065559983253479\n","0.6057318449020386\n","0.6026120781898499\n","0.6015635132789612\n","0.6017746925354004\n","0.5970532894134521\n","0.5938663482666016\n","0.5929431915283203\n","0.5917248725891113\n","0.5900125503540039\n","0.592244029045105\n","0.5850702524185181\n","0.5854201316833496\n","0.5791663527488708\n","0.5843324661254883\n","0.5805292725563049\n","0.5822051167488098\n","0.5782334208488464\n","0.5758771896362305\n","0.5751824378967285\n","0.5758291482925415\n","0.570422351360321\n","0.568662703037262\n","0.5689569711685181\n","0.5657864809036255\n","0.5653983354568481\n","0.5636566877365112\n","0.5642415285110474\n","0.5620338916778564\n","0.5613518953323364\n","0.5585448145866394\n","0.558102011680603\n","0.5563951730728149\n","0.5547580122947693\n","0.5529503226280212\n","0.5529323816299438\n","0.5507381558418274\n","0.5543153285980225\n","0.5490286350250244\n","0.5482875108718872\n","0.5463687181472778\n","0.5481712222099304\n","0.5455844402313232\n","0.5424076318740845\n","0.5433697700500488\n","0.542112410068512\n","0.5411430597305298\n","0.5414818525314331\n","0.5403597354888916\n","0.5367974042892456\n","0.5391248464584351\n","0.5363285541534424\n","0.5350999236106873\n","0.5320908427238464\n","0.5337502360343933\n","0.5320436954498291\n","0.531947672367096\n","0.5290299654006958\n","0.5254001021385193\n","0.5252420902252197\n","0.524879515171051\n","0.5264356136322021\n","0.5296661853790283\n","0.5274534225463867\n","0.5247049331665039\n","0.5197083353996277\n","0.5201805233955383\n","0.5195153951644897\n","0.5217955708503723\n","0.519368052482605\n","0.5186716318130493\n","0.5161552429199219\n","0.5173784494400024\n","0.5191065073013306\n","0.5158401131629944\n"]}],"source":["for epoch in range(1,200):\n","  loss = train_dgi()\n","  print(loss)"]},{"cell_type":"code","source":["with torch.no_grad():\n"," model_dgi.encoder.eval()\n"," tens = model_dgi.encoder(data.x, data.edge_index)"],"metadata":{"id":"gWd1YSHcnmXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(tens))\n","print(tens.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLPcGPp2n-Bf","executionInfo":{"status":"ok","timestamp":1675719835531,"user_tz":-120,"elapsed":8,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"0cdcde9e-641e-4626-ee30-652eed42d9e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","torch.Size([203769, 128])\n"]}]},{"cell_type":"code","source":["gat_emb = tens.tolist()\n"],"metadata":{"id":"PWQ6Ff3zoGW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","gat_emb = np.array(gat_emb)"],"metadata":{"id":"ytUUo9eCoNL-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import os\n","\n","os.chdir(\"/content/drive/MyDrive/Diplomatic2/Implementation/FINAL_RESULTS/DGI_EMB\")\n","!ls\n","architecture  = 'SAGE_DGI.emb'\n","file2save_everything = open(architecture,'wb')\n","pickle.dump(gat_emb,file2save_everything)\n","file2save_everything.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56jUbOPgoVQ2","executionInfo":{"status":"ok","timestamp":1675719857613,"user_tz":-120,"elapsed":1706,"user":{"displayName":"ALEXANDROS IASON KAMPANIS","userId":"12284258690784371067"}},"outputId":"dc199cb1-9d28-462b-dfc1-559b686799fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AGNN_DGI.emb  GAT_DGI.emb\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOQWu2YrJLDS"},"outputs":[],"source":["encode_obj2 = copy.deepcopy(model_dgi.encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D839mJU5_34H"},"outputs":[],"source":["AGNN_Class2 = AGNN_Classifier(encode_obj2).to(device)\n","print(AGNN_Class2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfspJV7rAd5-"},"outputs":[],"source":["#SCRIPT 7 \n","#TRAIN CLASSIFIERS WITH AND WITHOUT FREEZED PARAMETERS\n","losses, val_losses, best_model, accuracy_v, auc_v, recall_score_v, precission_score_v, f1_v = train2(AGNN_Class2,200,False)\n","auc_score_GAT, acc_GAT, rec_GAT, pre_GAT, f1_GAT, conf_m_GAT = test(best_model,data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZghKXi0G-LO","outputId":"1ce7ac47-8eb5-4a54-b25a-6b6a95d395a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9263032674789429 0.9358312487602234 [0.5324165225028992, 0.9745465517044067] [0.6674876809120178, 0.9559813737869263] [0.5923497080802917, 0.965174674987793] [[1355, 1190], [675, 25844]]\n"]}],"source":["print(auc_score_GAT, acc_GAT, rec_GAT, pre_GAT, f1_GAT, conf_m_GAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzkuXThLL5DQ"},"outputs":[],"source":["file2save_everything = open('agnn_train','wb')\n","#pickle.dump(best_model, file2save_everything)\n","#SAVE TRAIN DATA\n","pickle.dump(losses, file2save_everything)\n","pickle.dump(val_losses, file2save_everything)\n","pickle.dump(accuracy_v, file2save_everything)\n","pickle.dump(auc_v, file2save_everything)\n","pickle.dump(recall_score_v, file2save_everything)\n","pickle.dump(precission_score_v, file2save_everything)\n","pickle.dump(f1_v, file2save_everything)\n","#SAVE TEST DATA\n","pickle.dump(auc_score_GAT, file2save_everything)\n","pickle.dump(acc_GAT, file2save_everything)\n","pickle.dump(rec_GAT, file2save_everything)\n","pickle.dump(pre_GAT, file2save_everything)\n","pickle.dump(f1_GAT, file2save_everything)\n","pickle.dump(conf_m_GAT, file2save_everything)\n","\n","file2save_everything.close()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"9527dfccb63c89fcab4bb85d10820d37ed9c2952129a82128b597f23b43099db"}}},"nbformat":4,"nbformat_minor":0}